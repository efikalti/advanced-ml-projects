{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import logging\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define constants and initialize logging formatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 8520\n",
    "\n",
    "MOST_FREQ = 2\n",
    "MOST_FREQ_COUNT = 3181\n",
    "\n",
    "TRAIN_FILE = 'data/train-data.dat'\n",
    "TEST_FILE = 'data/test-data.dat'\n",
    "LABEL_TRAIN_FILE = 'data/train-label.dat'\n",
    "LABEL_TEST_FILE = 'data/test-label.dat'\n",
    "\n",
    "SAMPLE_COEF = 100\n",
    "\n",
    "# create formatter\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format='%(asctime)s.%(msecs)03d %(levelname)s - %(funcName)s: %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to read and preprocess input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read values for data from the provided file for the x and y values\n",
    "def ReadValues(x_filename, y_filename):\n",
    "\n",
    "    file_ids = FileIDs(x_filename)\n",
    "\n",
    "    # Read labels array\n",
    "    y_data = pd.read_csv(y_filename, header=None, delim_whitespace=True,\n",
    "                         error_bad_lines=False).values\n",
    "\n",
    "    # Create new array to hold the transformed data\n",
    "    x_data = []\n",
    "    y_data_transformed = []\n",
    "\n",
    "    index = 0\n",
    "    with open(x_filename) as file:\n",
    "        for line in file:\n",
    "            if index % SAMPLE_COEF == 0:\n",
    "\n",
    "                # Find the file id for this line\n",
    "                file = int(re.findall('^<([0-9]*)>', line)[0])\n",
    "\n",
    "                sentence = np.zeros((VOCAB_SIZE + 1), dtype=np.int32)\n",
    "                sentence[-1] = file\n",
    "\n",
    "                # Find label\n",
    "                if y_data[index][MOST_FREQ] == 1:\n",
    "                    label = 1\n",
    "                else:\n",
    "                    label = 0\n",
    "\n",
    "                # Split line into parts by whitespace\n",
    "                parts = line.split()\n",
    "                file_id = True\n",
    "                for part in parts:\n",
    "                    if part[0] != '<':\n",
    "                        # Set 1 for this word in this sentence\n",
    "                        sentence[int(part)] = 1\n",
    "                    else:\n",
    "                        if file_id is False:\n",
    "                            x_data.append(sentence)\n",
    "                            y_data_transformed.append(label)\n",
    "                            sentence = np.zeros((VOCAB_SIZE + 1), dtype=np.int32)\n",
    "                            sentence[-1] = file\n",
    "                        else:\n",
    "                            file_id = False\n",
    "            # Increase index\n",
    "            index += 1\n",
    "    return x_data, y_data_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the predicted labels for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateResults(data, results):\n",
    "    file_results = {}\n",
    "    index = 0\n",
    "    for result in results:\n",
    "        file_id = str(data[index][-1])\n",
    "        if file_id in file_results:\n",
    "            file_results[file_id][result] += 1\n",
    "        else:\n",
    "            file_results[file_id] = [0, 0]\n",
    "        index += 1\n",
    "    return file_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that returns the ids of all documents contained in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FileIDs(filename):\n",
    "    doc_ids = {}\n",
    "    index = 0\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            # Find the file id for this line\n",
    "            file = re.findall('^<([0-9]*)>', line)[0]\n",
    "            if file not in doc_ids:\n",
    "                doc_ids[file] = index\n",
    "                index += 1\n",
    "    return doc_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to run OneVsRestClassifier to create a model for every class vs all the other classes and then train a RandomForestClassifier for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PartB():\n",
    "    logging.info(\"Reading data\")\n",
    "    # Read train data\n",
    "    train_x, train_y = ReadValues(x_filename=TRAIN_FILE, y_filename=LABEL_TRAIN_FILE)\n",
    "\n",
    "    # Read test data\n",
    "    test_x, test_y = ReadValues(x_filename=TEST_FILE, y_filename=LABEL_TEST_FILE)\n",
    "\n",
    "    logging.info(\"Train SVM model\")\n",
    "    model = SVC(gamma='auto', class_weight=\"balanced\")\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    logging.info(\"Predict test data\")\n",
    "    y_predicted = model.predict(test_x)\n",
    "    acc = accuracy_score(test_y, y_predicted)\n",
    "    logging.info('Accuracy {0}:'.format(str(acc)))\n",
    "\n",
    "    logging.info(CalculateResults(test_x, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run PartA function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-18 00:04:54.507 INFO - PartB: Reading data\n",
      "2019-05-18 00:04:54.741 INFO - PartB: Train SVM model\n",
      "2019-05-18 00:05:09.313 INFO - PartB: Predict test data\n",
      "2019-05-18 00:05:16.736 INFO - PartB: Accuracy 0.5986577181208054:\n",
      "2019-05-18 00:05:16.738 INFO - PartB: {'31': [371, 0], '20': [39, 0], '4': [0, 11], '8': [0, 7], '19': [18, 0], '10': [0, 19], '12': [0, 23], '26': [25, 0], '29': [28, 0], '18': [0, 17], '5': [0, 14], '22': [21, 0], '30': [29, 0], '9': [0, 17], '16': [0, 15], '3': [0, 5], '25': [24, 0], '24': [23, 0], '14': [0, 13], '7': [0, 6]}\n"
     ]
    }
   ],
   "source": [
    "PartB()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
