{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Sensitive Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import csv\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CostClassification class\n",
    "Includes functions for LinearSVM, RandomForest and MultinomialNB algorithms\n",
    "Implements Stratification and RejectionSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CostClassification:\n",
    "\n",
    "    def __init__(self, data_x, data_y, cost_matrix, classA=1, classB=2):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.cost = cost_matrix\n",
    "        self.classA = classA\n",
    "        self.classB = classB\n",
    "        self.createData()\n",
    "        self.setupResults()\n",
    "        self.model = None\n",
    "        self.class_weight = {\n",
    "            classA: self.cost[0][1], classB: self.cost[1][0]}\n",
    "\n",
    "        # Set min and max keys\n",
    "        self.min_key = None\n",
    "        for key in self.class_weight:\n",
    "            if self.min_key is None:\n",
    "                self.min_key = key\n",
    "                self.min_pos = 0\n",
    "                self.max_pos = 1\n",
    "            else:\n",
    "                if self.class_weight[key] < self.class_weight[self.min_key]:\n",
    "                    self.min_key = key\n",
    "                    self.min_pos = 1\n",
    "                    self.max_pos = 0\n",
    "        for key in self.class_weight:\n",
    "            if self.min_key != key:\n",
    "                self.max_key = key\n",
    "        self.createSampleWeights(self.y_train)\n",
    "\n",
    "    def run(self, withClassWeight=True, withStratification=True, withRejectionSampling=True):\n",
    "\n",
    "        self.logDataInfo(self.y_train)\n",
    "\n",
    "        print(\"Run without using the cost matrix -----------------------------\")\n",
    "        self.runWithoutCost(method=\"Without Cost\")\n",
    "        print(\"\")\n",
    "\n",
    "        if withClassWeight is True:\n",
    "            print(\"Run using class weights as cost -------------------------------\")\n",
    "            self.runForClassWeights(method=\"With Class Weights\")\n",
    "            print(\"\")\n",
    "\n",
    "        if withStratification is True:\n",
    "            print(\"Run using Stratification - Combination ------------------------\")\n",
    "            self.runForStratification(method=\"With Stratification\")\n",
    "            print(\"\")\n",
    "\n",
    "        if withRejectionSampling is True:\n",
    "            print(\"Run using Rejection Sampling ----------------------------------\")\n",
    "            self.runForRejectionSampling(method=\"With Rejection Sampling\")\n",
    "            print(\"\")\n",
    "\n",
    "    def runWithoutCost(self, **kwargs):\n",
    "\n",
    "        print(\"Running Linear SVM without using the cost matrix\")\n",
    "        self.LinearSVM(with_class_weight=False, **kwargs)\n",
    "\n",
    "        print(\"Running Random Forest without using the cost matrix\")\n",
    "        self.RandomForest(with_class_weight=False, **kwargs)\n",
    "\n",
    "        print(\"Running Naive Bayes without using the cost matrix\")\n",
    "        self.NaiveBayes(with_class_weight=False, **kwargs)\n",
    "\n",
    "    def runForClassWeights(self, **kwargs):\n",
    "\n",
    "        print(\"Running Linear SVM using the cost matrix as class weights\")\n",
    "        self.LinearSVM(with_class_weight=True, **kwargs)\n",
    "\n",
    "        print(\"Running Random Forest using the cost matrix as class weights\")\n",
    "        self.RandomForest(with_class_weight=True, **kwargs)\n",
    "\n",
    "        print(\"Running Naive Bayes using the cost matrix as class weights\")\n",
    "        self.NaiveBayes(with_class_weight=True, **kwargs)\n",
    "\n",
    "    def runForStratification(self, **kwargs):\n",
    "        # Copy original sample set\n",
    "        x_train = np.copy(self.x_train)\n",
    "        y_train = np.copy(self.y_train)\n",
    "        # Log original dataset info\n",
    "        self.logDataInfo(self.y_train)\n",
    "        # Create new dataset\n",
    "        size = len(x_train) * 2\n",
    "        self.Stratification(size=size)\n",
    "        self.x_train = self.x_train_new\n",
    "        self.y_train = self.y_train_new\n",
    "        # Log new dataset info\n",
    "        self.logDataInfo(self.y_train_new)\n",
    "\n",
    "        print(\"Running Linear SVM for Stratification\")\n",
    "        self.LinearSVM(with_class_weight=False, **kwargs)\n",
    "\n",
    "        print(\"Running Random Forest for Stratification\")\n",
    "        self.RandomForest(with_class_weight=False, **kwargs)\n",
    "\n",
    "        print(\"Running Naive Bayes for Stratification\")\n",
    "        self.NaiveBayes(with_class_weight=False, **kwargs)\n",
    "\n",
    "        # Restore original data\n",
    "        self.x_train = np.copy(x_train)\n",
    "        self.y_train = np.copy(y_train)\n",
    "\n",
    "    def runForRejectionSampling(self, **kwargs):\n",
    "        # Copy original sample set\n",
    "        x_train = np.copy(self.x_train)\n",
    "        y_train = np.copy(self.y_train)\n",
    "        # Log original dataset info\n",
    "        self.logDataInfo(self.y_train)\n",
    "        # Create new dataset\n",
    "        self.RejectionSampling()\n",
    "        self.x_train = self.x_train_new\n",
    "        self.y_train = self.y_train_new\n",
    "        # Log new dataset info\n",
    "        self.logDataInfo(self.y_train_new)\n",
    "\n",
    "        print(\"Running Linear SVM\")\n",
    "        self.LinearSVM(with_class_weight=False, **kwargs)\n",
    "\n",
    "        print(\"Running Random Forest\")\n",
    "        self.RandomForest(with_class_weight=False, **kwargs)\n",
    "\n",
    "        print(\"Running Naive Bayes\")\n",
    "        self.NaiveBayes(with_class_weight=False, **kwargs)\n",
    "\n",
    "        self.x_train = np.copy(x_train)\n",
    "        self.y_train = np.copy(y_train)\n",
    "\n",
    "    def NaiveBayes(self, with_class_weight=True, **kwargs):\n",
    "        # Create model using class weights according to the cost matrix\n",
    "        self.model = MultinomialNB()\n",
    "        self.train(with_class_weight=with_class_weight, algorithm='NaiveBayes', **kwargs)\n",
    "\n",
    "    def RandomForest(self, with_class_weight=True, **kwargs):\n",
    "        if with_class_weight is True:\n",
    "            # Create model using class weights according to the cost matrix\n",
    "            self.model = RandomForestClassifier(\n",
    "                class_weight=self.class_weight, n_estimators=10, random_state=0)\n",
    "        else:\n",
    "            self.model = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "        self.train(algorithm='RandomForest', **kwargs)\n",
    "\n",
    "    def LinearSVM(self, with_class_weight=True, **kwargs):\n",
    "        if with_class_weight is True:\n",
    "            # Create model using class weights according to the cost matrix\n",
    "            self.model = SVC(random_state=0, class_weight=self.class_weight, kernel='linear')\n",
    "        else:\n",
    "            # Create model without class weights\n",
    "            self.model = SVC(random_state=0, kernel='linear')\n",
    "        self.train(algorithm='LinearSVM', **kwargs)\n",
    "\n",
    "    def train(self, with_class_weight=False, **kwargs):\n",
    "        # Fit model using train data\n",
    "        if with_class_weight is False:\n",
    "            self.model.fit(self.x_train, self.y_train)\n",
    "        else:\n",
    "            self.model.fit(self.x_train, self.y_train, sample_weight=self.weights)\n",
    "        # Predict on train\n",
    "        self.y_predicted_train = self.model.predict(self.x_train)\n",
    "        # Predict on test\n",
    "        self.y_predicted_test = self.model.predict(self.x_test)\n",
    "        # Log results\n",
    "        self.logResults(**kwargs)\n",
    "\n",
    "    # Modify the data so the frequency of each class is analogous to its misclassification cost\n",
    "    def Stratification(self, size=None):\n",
    "        if size is None:\n",
    "            # Set the size the same as the current sample\n",
    "            size = len(self.x_train)\n",
    "        if size <= 0:\n",
    "            # Set the size the same as the current sample\n",
    "            size = len(self.x_train)\n",
    "\n",
    "        # Calculate the ratio between the classes samples\n",
    "        ratio = self.class_weight[self.max_key] / self.class_weight[self.min_key]\n",
    "\n",
    "        # Calculate the number of samples for each class\n",
    "        cost_sum = ratio + 1\n",
    "        max_cost_size = math.floor(size / cost_sum) * ratio + (size % cost_sum)\n",
    "        min_cost_size = math.floor(size / cost_sum)\n",
    "\n",
    "        self.x_train_new = []\n",
    "        self.y_train_new = []\n",
    "        while max_cost_size > 0 or min_cost_size > 0:\n",
    "            # Select a random sample\n",
    "            sample = random.randint(0, len(self.y_train)-1)\n",
    "            if self.y_train[sample] == self.min_key:\n",
    "                if min_cost_size > 0:\n",
    "                    self.x_train_new.append(self.x_train[sample])\n",
    "                    self.y_train_new.append(self.y_train[sample])\n",
    "                    min_cost_size -= 1\n",
    "            else:\n",
    "                if max_cost_size > 0:\n",
    "                    self.x_train_new.append(self.x_train[sample])\n",
    "                    self.y_train_new.append(self.y_train[sample])\n",
    "                    max_cost_size -= 1\n",
    "\n",
    "    # Rejection sampling with z = max cost\n",
    "    def RejectionSampling(self):\n",
    "        size = len(self.x_train)\n",
    "\n",
    "        # Set z\n",
    "        z = self.class_weight[self.max_key]\n",
    "\n",
    "        self.x_train_new = []\n",
    "        self.y_train_new = []\n",
    "        for index in range(0, size):\n",
    "            value = self.class_weight[self.y_train[index]] / z\n",
    "            prob = random.uniform(0, 1)\n",
    "            if (value >= prob):\n",
    "                self.x_train_new.append(self.x_train[index])\n",
    "                self.y_train_new.append(self.y_train[index])\n",
    "\n",
    "    def createSampleWeights(self, y):\n",
    "        self.weights = np.array(y)\n",
    "        index = 0\n",
    "        for sample in y:\n",
    "            self.weights[index] = self.class_weight[sample]\n",
    "            index += 1\n",
    "\n",
    "    def logResults(self, method, algorithm):\n",
    "        result_train = metrics.accuracy_score(self.y_train, self.y_predicted_train)\n",
    "        result_test = metrics.accuracy_score(self.y_test, self.y_predicted_test)\n",
    "        print(\"Training results: \" + str(result_train) + \" acc\")\n",
    "\n",
    "        print(\"Test results: \" + str(result_test) + \" acc\")\n",
    "        confusion_matrix = metrics.confusion_matrix(\n",
    "            self.y_test, self.y_predicted_test, labels=[self.classA, self.classB])\n",
    "        print(confusion_matrix)\n",
    "        self.results = self.results.append({'Cost Sensitive Method': method, 'Algorithm': algorithm, 'Accuracy train':  float(\n",
    "            \"%0.3f\" % result_train), 'Accuracy test': float(\"%0.3f\" % result_test),\n",
    "            'True max cost': confusion_matrix[self.max_pos][self.max_pos], 'False max cost': confusion_matrix[self.max_pos][self.min_pos],\n",
    "            'True min cost': confusion_matrix[self.min_pos][self.min_pos], 'False min cost': confusion_matrix[self.min_pos][self.max_pos],\n",
    "            'Sample size': len(self.x_train), 'Max cost sample': self.max_sum, 'Min cost sample': self.min_sum}, ignore_index=True)\n",
    "\n",
    "        print(\"---------------------------------------------------------------\")\n",
    "\n",
    "    def logDataInfo(self, y):\n",
    "        self.min_sum = 0\n",
    "        self.max_sum = 0\n",
    "        for sample in y:\n",
    "            if sample == self.min_key:\n",
    "                self.min_sum += 1\n",
    "            else:\n",
    "                self.max_sum += 1\n",
    "        print(\"Sample size:\" + str(len(self.x_train)))\n",
    "        print(\"Max cost sample size:\" + str(self.max_sum))\n",
    "        print(\"Min cost sample size:\" + str(self.min_sum))\n",
    "        print(\"\")\n",
    "\n",
    "    def createData(self):\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.data_x, self.data_y, test_size=0.30)\n",
    "\n",
    "    def setupResults(self):\n",
    "        self.results = pd.DataFrame(\n",
    "            columns=['Cost Sensitive Method', 'Algorithm', 'Accuracy train', 'Accuracy test',\n",
    "                     'True max cost', 'False max cost', 'True min cost', 'False min cost',\n",
    "                     'Sample size', 'Max cost sample', 'Min cost sample'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to scale data between 0 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleData(x):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    scaled_x = min_max_scaler.fit_transform(x)\n",
    "    return scaled_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "costSensitive function loads the cost sensitive data, creates the cost matrix and the CostClassification object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def costSensitive():\n",
    "    \"\"\" Assignment Part B \"\"\"\n",
    "\n",
    "    # read data/heart.csv\n",
    "    data = pd.read_csv(\"data/heart.csv\", sep=\",\", dtype='float')\n",
    "    data\n",
    "    data_x = data.values[:, :-1]\n",
    "    data_y = data.values[:, -1].astype(int)\n",
    "\n",
    "    data_x = scaleData(data_x)\n",
    "\n",
    "    cost_matrix = [[0, 1], [5, 0]]\n",
    "    costClassifier = CostClassification(data_x, data_y, cost_matrix)\n",
    "    costClassifier.run(withClassWeight=True, withStratification=True, withRejectionSampling=True)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(costClassifier.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run costSensitive function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size:188\n",
      "Max cost sample size:85\n",
      "Min cost sample size:103\n",
      "\n",
      "Run without using the cost matrix -----------------------------\n",
      "Running Linear SVM without using the cost matrix\n",
      "Training results: 0.8457446808510638 acc\n",
      "Test results: 0.8518518518518519 acc\n",
      "[[41  6]\n",
      " [ 6 28]]\n",
      "---------------------------------------------------------------\n",
      "Running Random Forest without using the cost matrix\n",
      "Training results: 1.0 acc\n",
      "Test results: 0.7037037037037037 acc\n",
      "[[33 14]\n",
      " [10 24]]\n",
      "---------------------------------------------------------------\n",
      "Running Naive Bayes without using the cost matrix\n",
      "Training results: 0.8031914893617021 acc\n",
      "Test results: 0.8518518518518519 acc\n",
      "[[40  7]\n",
      " [ 5 29]]\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Run using class weights as cost -------------------------------\n",
      "Running Linear SVM using the cost matrix as class weights\n",
      "Training results: 0.7925531914893617 acc\n",
      "Test results: 0.8148148148148148 acc\n",
      "[[36 11]\n",
      " [ 4 30]]\n",
      "---------------------------------------------------------------\n",
      "Running Random Forest using the cost matrix as class weights\n",
      "Training results: 0.9946808510638298 acc\n",
      "Test results: 0.7407407407407407 acc\n",
      "[[35 12]\n",
      " [ 9 25]]\n",
      "---------------------------------------------------------------\n",
      "Running Naive Bayes using the cost matrix as class weights\n",
      "Training results: 0.4574468085106383 acc\n",
      "Test results: 0.41975308641975306 acc\n",
      "[[ 0 47]\n",
      " [ 0 34]]\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Run using Stratification - Combination ------------------------\n",
      "Sample size:188\n",
      "Max cost sample size:85\n",
      "Min cost sample size:103\n",
      "\n",
      "Sample size:376\n",
      "Max cost sample size:314\n",
      "Min cost sample size:62\n",
      "\n",
      "Running Linear SVM for Stratification\n",
      "Training results: 0.9335106382978723 acc\n",
      "Test results: 0.691358024691358 acc\n",
      "[[23 24]\n",
      " [ 1 33]]\n",
      "---------------------------------------------------------------\n",
      "Running Random Forest for Stratification\n",
      "Training results: 1.0 acc\n",
      "Test results: 0.6666666666666666 acc\n",
      "[[25 22]\n",
      " [ 5 29]]\n",
      "---------------------------------------------------------------\n",
      "Running Naive Bayes for Stratification\n",
      "Training results: 0.8351063829787234 acc\n",
      "Test results: 0.41975308641975306 acc\n",
      "[[ 0 47]\n",
      " [ 0 34]]\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Run using Rejection Sampling ----------------------------------\n",
      "Sample size:188\n",
      "Max cost sample size:85\n",
      "Min cost sample size:103\n",
      "\n",
      "Sample size:104\n",
      "Max cost sample size:85\n",
      "Min cost sample size:19\n",
      "\n",
      "Running Linear SVM\n",
      "Training results: 0.9326923076923077 acc\n",
      "Test results: 0.7530864197530864 acc\n",
      "[[29 18]\n",
      " [ 2 32]]\n",
      "---------------------------------------------------------------\n",
      "Running Random Forest\n",
      "Training results: 0.9903846153846154 acc\n",
      "Test results: 0.6172839506172839 acc\n",
      "[[18 29]\n",
      " [ 2 32]]\n",
      "---------------------------------------------------------------\n",
      "Running Naive Bayes\n",
      "Training results: 0.8173076923076923 acc\n",
      "Test results: 0.41975308641975306 acc\n",
      "[[ 0 47]\n",
      " [ 0 34]]\n",
      "---------------------------------------------------------------\n",
      "\n",
      "\n",
      "      Cost Sensitive Method     Algorithm  Accuracy train  Accuracy test  \\\n",
      "0              Without Cost     LinearSVM           0.846          0.852   \n",
      "1              Without Cost  RandomForest           1.000          0.704   \n",
      "2              Without Cost    NaiveBayes           0.803          0.852   \n",
      "3        With Class Weights     LinearSVM           0.793          0.815   \n",
      "4        With Class Weights  RandomForest           0.995          0.741   \n",
      "5        With Class Weights    NaiveBayes           0.457          0.420   \n",
      "6       With Stratification     LinearSVM           0.934          0.691   \n",
      "7       With Stratification  RandomForest           1.000          0.667   \n",
      "8       With Stratification    NaiveBayes           0.835          0.420   \n",
      "9   With Rejection Sampling     LinearSVM           0.933          0.753   \n",
      "10  With Rejection Sampling  RandomForest           0.990          0.617   \n",
      "11  With Rejection Sampling    NaiveBayes           0.817          0.420   \n",
      "\n",
      "   True max cost False max cost True min cost False min cost Sample size  \\\n",
      "0             28              6            41              6         188   \n",
      "1             24             10            33             14         188   \n",
      "2             29              5            40              7         188   \n",
      "3             30              4            36             11         188   \n",
      "4             25              9            35             12         188   \n",
      "5             34              0             0             47         188   \n",
      "6             33              1            23             24         376   \n",
      "7             29              5            25             22         376   \n",
      "8             34              0             0             47         376   \n",
      "9             32              2            29             18         104   \n",
      "10            32              2            18             29         104   \n",
      "11            34              0             0             47         104   \n",
      "\n",
      "   Max cost sample Min cost sample  \n",
      "0               85             103  \n",
      "1               85             103  \n",
      "2               85             103  \n",
      "3               85             103  \n",
      "4               85             103  \n",
      "5               85             103  \n",
      "6              314              62  \n",
      "7              314              62  \n",
      "8              314              62  \n",
      "9               85              19  \n",
      "10              85              19  \n",
      "11              85              19  \n"
     ]
    }
   ],
   "source": [
    "costSensitive()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
