{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble \n",
    "Includes functions for 10-fold cross validation, ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensembles:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.bagging = None\n",
    "        self.boosting = None\n",
    "        self.randomForest = None\n",
    "        self.voting = None\n",
    "        self.ensembles = [\"AdaBoost\", \"Bagging\", \"RandomForest\", \"Voting\"]\n",
    "        self.iterations = 10\n",
    "\n",
    "        # Results\n",
    "        self.accuracy_results = pd.DataFrame(\n",
    "            columns=['Dataset', 'AdaBoost', 'Bagging', 'RandomForest', 'Voting'])\n",
    "\n",
    "        # Data\n",
    "        self.x_train = None\n",
    "        self.x_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "\n",
    "        # Prediction data\n",
    "        self.y_predicted_train = None\n",
    "        self.y_predicted_test = None\n",
    "\n",
    "    def train(self, data_x, data_y, boosting=True, bagging=True, randomForest=True, voting=True, dataset=\"\"):\n",
    "        self.dataset = dataset\n",
    "        self.setupResults()\n",
    "\n",
    "        # Execute 10-fold cross validation and keep the mean score of train and test accuracy\n",
    "        for i in range(0, self.iterations):\n",
    "            # Create new data split\n",
    "            self.createData(data_x, data_y)\n",
    "            # Train and predict using Boosting ensemble\n",
    "            if boosting is True:\n",
    "                # Create model\n",
    "                self.boosting = AdaBoostClassifier(random_state=0)\n",
    "                # Train predict and log results for this model\n",
    "                self.fitPredict(self.boosting, \"AdaBoost\")\n",
    "            # Train and predict using RandomForest ensemble\n",
    "            if randomForest is True:\n",
    "                # Create model\n",
    "                self.randomForest = RandomForestClassifier(\n",
    "                    random_state=0, n_estimators=50)\n",
    "                # Train predict and log results for this model\n",
    "                self.fitPredict(self.randomForest, \"RandomForest\")\n",
    "            # Train and predict using Bagging ensemble\n",
    "            if bagging is True:\n",
    "                # Create model\n",
    "                self.bagging = BaggingClassifier(\n",
    "                    random_state=0)\n",
    "                # Train predict and log results for this model\n",
    "                self.fitPredict(self.bagging, \"Bagging\")\n",
    "            if voting is True:\n",
    "                # Train and predict using Voting ensemble\n",
    "                rf = RandomForestClassifier(random_state=0, n_estimators=10)\n",
    "                knn = KNeighborsClassifier()\n",
    "                svc = SVC(random_state=0, gamma='auto')\n",
    "                mnb = MultinomialNB()\n",
    "\n",
    "                self.voting = VotingClassifier(estimators=[(\n",
    "                    'Random Forests', rf), ('KNeighbors', knn), ('SVC', svc), ('MultinomialNB', mnb)], voting='hard')\n",
    "                # Train predict and log results for this model\n",
    "                self.fitPredict(self.voting, \"Voting\")\n",
    "\n",
    "        # Calculate mean for each ensemble\n",
    "        self.meanResults()\n",
    "\n",
    "        # Log final results\n",
    "        for ensembe in self.ensembles:\n",
    "            self.logEnsembleResults(ensembe)\n",
    "        self.logResults()\n",
    "        self.printEnsembleResults()\n",
    "\n",
    "    def fitPredict(self, model, name):\n",
    "        # Train model\n",
    "        model.fit(self.x_train, self.y_train)\n",
    "        # Predict\n",
    "        self.y_predicted_train = model.predict(self.x_train)\n",
    "        self.y_predicted_test = model.predict(self.x_test)\n",
    "        # Log results\n",
    "        self.addResults(name)\n",
    "\n",
    "    def createData(self, data_x, data_y):\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(\n",
    "            data_x, data_y, test_size=0.30, random_state=0)\n",
    "\n",
    "    def addResults(self, name):\n",
    "        result_train = metrics.accuracy_score(self.y_train, self.y_predicted_train)\n",
    "        result_test = metrics.accuracy_score(self.y_test, self.y_predicted_test)\n",
    "        self.results[name][\"train\"] += result_train\n",
    "        self.results[name][\"test\"] += result_test\n",
    "\n",
    "    def meanResults(self):\n",
    "        for ensemble in self.ensembles:\n",
    "            self.results[ensemble][\"train\"] /= self.iterations\n",
    "            self.results[ensemble][\"test\"] /= self.iterations\n",
    "        self.calculateRanking()\n",
    "\n",
    "    def calculateRanking(self):\n",
    "        ensembles = self.ensembles.copy()\n",
    "        i = 1\n",
    "        while len(ensembles) > 0:\n",
    "            max_ensemble = None\n",
    "            duplicates = 0\n",
    "            for ensemble in ensembles:\n",
    "                if max_ensemble == None:\n",
    "                    max_ensemble = ensemble\n",
    "                else:\n",
    "                    if self.results[max_ensemble][\"test\"] < self.results[ensemble][\"test\"]:\n",
    "                        max_ensemble = ensemble\n",
    "                        duplicates = 0\n",
    "                    elif self.results[max_ensemble][\"test\"] == self.results[ensemble][\"test\"]:\n",
    "                        duplicates += 1\n",
    "            if duplicates == 0:\n",
    "                self.ranking[max_ensemble] = \" (\" + str(i) + \")\"\n",
    "                ensembles.remove(max_ensemble)\n",
    "            else:\n",
    "                duplicates += 1\n",
    "                ranking = i + (1 / duplicates)\n",
    "                j = 0\n",
    "                while duplicates > 0:\n",
    "                    if self.results[max_ensemble][\"test\"] == self.results[ensembles[j]][\"test\"]:\n",
    "                        self.ranking[ensembles[j]] = \" (\" + str(ranking) + \")\"\n",
    "                        ensembles.remove(ensembles[j])\n",
    "                        duplicates -= 1\n",
    "                    else:\n",
    "                        j += 1\n",
    "            i += 1\n",
    "\n",
    "    def logResults(self):\n",
    "        self.accuracy_results = self.accuracy_results.append({\n",
    "            'Dataset': self.dataset,\n",
    "            self.ensembles[0]: str(float(\"%0.4f\" % self.results[self.ensembles[0]][\"test\"])) + self.ranking[self.ensembles[0]],\n",
    "            self.ensembles[1]: str(float(\"%0.4f\" % self.results[self.ensembles[1]][\"test\"])) + self.ranking[self.ensembles[1]],\n",
    "            self.ensembles[2]: str(float(\"%0.4f\" % self.results[self.ensembles[2]][\"test\"])) + self.ranking[self.ensembles[2]],\n",
    "            self.ensembles[3]: str(float(\"%0.4f\" % self.results[self.ensembles[3]][\"test\"])) + self.ranking[self.ensembles[3]]}, ignore_index=True)\n",
    "\n",
    "    def logEnsembleResults(self, name):\n",
    "        self.ensemble_results = self.ensemble_results.append({'Algorithm': name, 'Mean accuracy train':  float(\n",
    "            \"%0.3f\" % self.results[name][\"train\"]), 'Mean accuracy test': float(\"%0.3f\" % self.results[name][\"test\"])}, ignore_index=True)\n",
    "\n",
    "    def printEnsembleResults(self):\n",
    "        # Print final results\n",
    "        print(self.ensemble_results)\n",
    "\n",
    "    def printResults(self):\n",
    "        # Print final results\n",
    "        print(self.accuracy_results)\n",
    "        print(\"\")\n",
    "\n",
    "    def setupResults(self):\n",
    "        self.ensemble_results = pd.DataFrame(\n",
    "            columns=['Algorithm', 'Mean accuracy train', 'Mean accuracy test'])\n",
    "        self.results = {\"Bagging\": {\"train\": 0, \"test\": 0}, \"AdaBoost\": {\n",
    "            \"train\": 0, \"test\": 0}, \"Voting\": {\"train\": 0, \"test\": 0}, \"RandomForest\": {\"train\": 0, \"test\": 0}}\n",
    "        self.ranking = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to scale data between 0 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleData(x):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    scaled_x = min_max_scaler.fit_transform(x)\n",
    "    return scaled_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runs the ensemble classifiers for the given dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runEnsembleForDataset(ensemble, dataset=None, name=\"\", data_x=None, data_y=None):\n",
    "    if dataset is not None:\n",
    "        data_x = dataset['data']\n",
    "        data_y = dataset['target']\n",
    "    data_x = scaleData(data_x)\n",
    "    ensemble.train(data_x, data_y, dataset=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partA function creates the ClassImbalance object, loads each data and calls runEnsembleForDataset function to run the ensemble for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def partA():\n",
    "    \"\"\" Assignment Part A \"\"\"\n",
    "\n",
    "    # Create ensemble object\n",
    "    ensemble = Ensembles()\n",
    "\n",
    "    print(\"1.Iris dataset\")\n",
    "    runEnsembleForDataset(ensemble, dataset=datasets.load_iris(), name=\"iris\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"2.Wine dataset\")\n",
    "    runEnsembleForDataset(ensemble, dataset=datasets.load_wine(), name=\"wine\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"3.Digits dataset\")\n",
    "    runEnsembleForDataset(ensemble, dataset=datasets.load_digits(), name=\"digits\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"4.Breast cancer dataset\")\n",
    "    runEnsembleForDataset(ensemble, dataset=datasets.load_breast_cancer(), name=\"breast cancer\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"5.Abalone dataset\")\n",
    "    # read data/abalone.data\n",
    "    data = pd.read_csv(\"data/abalone.data\", sep=\",\")\n",
    "    data_x = data.values[:, :-1]\n",
    "    data_y = data.values[:, -1].astype('int')\n",
    "    for i in range(0, len(data_x)):\n",
    "        if data_x[i, 0] == 'M':\n",
    "            data_x[i, 0] = 0\n",
    "        elif data_x[i, 0] == 'F':\n",
    "            data_x[i, 0] = 1\n",
    "        else:\n",
    "            data_x[i, 0] = 2\n",
    "    runEnsembleForDataset(ensemble, data_x=data_x, data_y=data_y, name=\"abalone\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"6.Heart dataset\")\n",
    "    # read data/heart.csv\n",
    "    data = pd.read_csv(\"data/heart.csv\", sep=\",\")\n",
    "    data_x = data.values[:, :-1]\n",
    "    data_y = data.values[:, -1]\n",
    "    runEnsembleForDataset(ensemble, data_x=data_x, data_y=data_y, name=\"heart\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"7.Glass dataset\")\n",
    "    # read data/glass.data\n",
    "    data = pd.read_csv(\"data/glass.data\", sep=\",\")\n",
    "    data_x = data.values[:, :-1]\n",
    "    data_y = data.values[:, -1]\n",
    "    runEnsembleForDataset(ensemble, data_x=data_x, data_y=data_y, name=\"glass\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"8.Transfusion dataset\")\n",
    "    # read data/transfusion.data\n",
    "    data = pd.read_csv(\"data/transfusion.data\", sep=\",\")\n",
    "    data_x = data.values[:, :-1]\n",
    "    data_y = data.values[:, -1]\n",
    "    runEnsembleForDataset(ensemble, data_x=data_x, data_y=data_y, name=\"transfusion\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"9.Starcraft dataset\")\n",
    "    # read data/SkillCraft1_Dataset.csv\n",
    "    data = pd.read_csv(\"data/SkillCraft1_Dataset.csv\", sep=\",\", na_values=['?'])\n",
    "    data_x = data.iloc[:, 2:]\n",
    "    data_x = data_x.fillna(data_x.mean())\n",
    "    data_x = data_x.values\n",
    "    data_y = data.values[:, 1]\n",
    "    runEnsembleForDataset(ensemble, data_x=data_x, data_y=data_y, name=\"starcraft\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"10.Credit Card dataset\")\n",
    "    # read data/creditcard.csv\n",
    "    data = pd.read_csv(\"data/creditcard.csv\", sep=\",\")\n",
    "    data_x = data.values[:100000, :-1]\n",
    "    data_y = data.values[:100000, -1]\n",
    "    runEnsembleForDataset(ensemble, data_x=data_x, data_y=data_y, name=\"credit card\")\n",
    "    print(\"\")\n",
    "\n",
    "    ensemble.printResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run partA function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Iris dataset\n",
      "      Algorithm  Mean accuracy train  Mean accuracy test\n",
      "0      AdaBoost                0.962               0.911\n",
      "1       Bagging                0.981               0.956\n",
      "2  RandomForest                1.000               0.978\n",
      "3        Voting                0.962               0.978\n",
      "\n",
      "2.Wine dataset\n",
      "      Algorithm  Mean accuracy train  Mean accuracy test\n",
      "0      AdaBoost                0.976               0.889\n",
      "1       Bagging                1.000               0.981\n",
      "2  RandomForest                1.000               1.000\n",
      "3        Voting                0.984               1.000\n",
      "\n",
      "3.Digits dataset\n",
      "      Algorithm  Mean accuracy train  Mean accuracy test\n",
      "0      AdaBoost                0.296               0.259\n",
      "1       Bagging                0.998               0.924\n",
      "2  RandomForest                1.000               0.972\n",
      "3        Voting                0.986               0.963\n",
      "\n",
      "4.Breast cancer dataset\n",
      "      Algorithm  Mean accuracy train  Mean accuracy test\n",
      "0      AdaBoost                1.000               0.965\n",
      "1       Bagging                0.992               0.942\n",
      "2  RandomForest                0.997               0.965\n",
      "3        Voting                0.980               0.953\n",
      "\n",
      "5.Abalone dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\edour\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Algorithm  Mean accuracy train  Mean accuracy test\n",
      "0      AdaBoost                0.220               0.204\n",
      "1       Bagging                0.979               0.224\n",
      "2  RandomForest                1.000               0.246\n",
      "3        Voting                0.465               0.231\n",
      "\n",
      "6.Heart dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\edour\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Algorithm  Mean accuracy train  Mean accuracy test\n",
      "0      AdaBoost                0.947               0.753\n",
      "1       Bagging                0.984               0.753\n",
      "2  RandomForest                1.000               0.852\n",
      "3        Voting                0.878               0.802\n",
      "\n",
      "7.Glass dataset\n",
      "      Algorithm  Mean accuracy train  Mean accuracy test\n",
      "0      AdaBoost                0.819               0.812\n",
      "1       Bagging                1.000               0.984\n",
      "2  RandomForest                1.000               0.984\n",
      "3        Voting                0.839               0.828\n",
      "\n",
      "8.Transfusion dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\edour\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Algorithm  Mean accuracy train  Mean accuracy test\n",
      "0      AdaBoost                0.793               0.760\n",
      "1       Bagging                0.927               0.711\n",
      "2  RandomForest                0.941               0.729\n",
      "3        Voting                0.776               0.729\n",
      "\n",
      "9.Starcraft dataset\n",
      "      Algorithm  Mean accuracy train  Mean accuracy test\n",
      "0      AdaBoost                0.218               0.217\n",
      "1       Bagging                0.992               0.407\n",
      "2  RandomForest                1.000               0.422\n",
      "3        Voting                0.604               0.358\n",
      "\n",
      "10.Credit Card dataset\n",
      "      Algorithm  Mean accuracy train  Mean accuracy test\n",
      "0      AdaBoost                0.999               0.999\n",
      "1       Bagging                1.000               1.000\n",
      "2  RandomForest                1.000               1.000\n",
      "3        Voting                0.999               0.999\n",
      "\n",
      "         Dataset      AdaBoost       Bagging  RandomForest        Voting\n",
      "0           iris    0.9111 (3)    0.9556 (2)  0.9778 (1.5)  0.9778 (1.5)\n",
      "1           wine    0.8889 (3)    0.9815 (2)     1.0 (1.5)     1.0 (1.5)\n",
      "2         digits    0.2593 (4)    0.9241 (3)    0.9722 (1)     0.963 (2)\n",
      "3  breast cancer  0.9649 (1.5)    0.9415 (3)  0.9649 (1.5)    0.9532 (2)\n",
      "4        abalone    0.2043 (4)    0.2243 (3)    0.2458 (1)    0.2314 (2)\n",
      "5          heart  0.7531 (3.5)  0.7531 (3.5)    0.8519 (1)    0.8025 (2)\n",
      "6          glass    0.8125 (3)  0.9844 (1.5)  0.9844 (1.5)    0.8281 (2)\n",
      "7    transfusion      0.76 (1)    0.7111 (3)  0.7289 (2.5)  0.7289 (2.5)\n",
      "8      starcraft    0.2169 (4)    0.4073 (2)     0.422 (1)    0.3582 (3)\n",
      "9    credit card    0.9995 (3)    0.9997 (2)    0.9998 (1)     0.999 (4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "partA()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
